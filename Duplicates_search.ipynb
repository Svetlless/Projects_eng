{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple code was written for a research project we were working on. The goal was to identify and handle duplicate data entries while ensuring all necessary information was retained for verification against the original dataset, using unique IDs as the primary reference. Each row of the data included a unique ID (шт еру first column) and a set of data collected during the research project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('Data.csv',sep = ';',encoding='latin-1',skip_blank_lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform ID into an index, so that it won't affect the duplicates search\n",
    "test = test.set_index('ID')\n",
    "#Now we can delete the rows where ID is the only information available\n",
    "test.dropna(axis = 0, how = 'all', inplace = True)\n",
    "#Now we look for duplicated data, keeping both variants in the output in order to verify them against the original data\n",
    "test.loc[test.duplicated(keep = False)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
